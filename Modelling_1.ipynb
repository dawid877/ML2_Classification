{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9e9501",
   "metadata": {},
   "source": [
    "# Target variable definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e385e1a",
   "metadata": {},
   "source": [
    "At this point, let's think what actually do we want to treat as our target variable\n",
    "1. We will start not by a classification task, but the regression one, with general_drug_usage index as our target\n",
    "2. Next, we will have a classical binary problem - recent drug user (=<1 year) or not.\n",
    "3. At the end, the same task as in the 3rd point but with adding other drugs to independent variables group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b1acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8e338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "X = pd.read_csv('Data/X.csv')\n",
    "y = pd.read_csv('Data/y.csv')\n",
    "y_binary = pd.read_csv('Data/y_binary.csv')\n",
    "y_decoded = pd.read_csv('Data/y_decoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536d170",
   "metadata": {},
   "source": [
    "# Problem 1. Regression - general_drug_index as target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9257955",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e312613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>impuslive</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   gender  education  country  ethnicity   nscore   escore   oscore  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    ascore   cscore  impuslive       ss  \n",
       "0 -0.91699 -0.00665   -0.21712 -1.18084  \n",
       "1  0.76096 -0.14277   -0.71126 -0.21575  \n",
       "2 -1.62090 -1.01450   -1.37983  0.40148  \n",
       "3  0.59042  0.58489   -1.37983 -1.18084  \n",
       "4 -0.30172  1.30612   -0.21712 -0.21575  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3465a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       22\n",
       "1       43\n",
       "2       20\n",
       "3       24\n",
       "4       27\n",
       "        ..\n",
       "1880    29\n",
       "1881    40\n",
       "1882    58\n",
       "1883    38\n",
       "1884    48\n",
       "Name: general_drug_usage, Length: 1885, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = y_decoded['general_drug_usage']\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ab7253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_decoded['general_drug_usage'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c0d36",
   "metadata": {},
   "source": [
    "## Algo 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f5ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_1,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5536e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.92117549 11.23507723  9.73106139 11.36978976 11.08213804]\n",
      "10.867848383042872\n"
     ]
    }
   ],
   "source": [
    "# Define the algorithm\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train regression with 5-fold cross validation\n",
    "scores = cross_val_score(lin_reg, X_train, y_train,\n",
    "scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(rmse_scores)\n",
    "print(rmse_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b53066",
   "metadata": {},
   "source": [
    "On average, predictions are off by ±11 units\n",
    "\n",
    "That’s roughly:\n",
    "\n",
    "~14% of the full range (80)\n",
    "\n",
    "~20–30% of the typical values (30–40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cb8e3",
   "metadata": {},
   "source": [
    "## Algo 2. Single Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9effde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE per fold: [12.09662686 11.85265864 10.62408887 11.97360749 11.98508075]\n",
      "Mean RMSE: 11.706412520348836\n",
      "Std RMSE: 0.5466495741950388\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "tree = DecisionTreeRegressor(\n",
    "    max_depth=5,      # control complexity\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# cross validation on the training set\n",
    "scores = cross_val_score(\n",
    "    tree,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "# Summarize performace\n",
    "print(\"RMSE per fold:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Std RMSE:\", rmse_scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43150619",
   "metadata": {},
   "source": [
    "## Algo 3. Random forest with OOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95352ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                      random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    oob_score=True,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e91ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.977186094517611"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob_pred = rf.oob_prediction_\n",
    "rmse = root_mean_squared_error(y_train, oob_pred)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5271f623",
   "metadata": {},
   "source": [
    "# Problem 2. Classification: recent drug user (less or equal than 1 year?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1fc6f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9252918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>impuslive</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   gender  education  country  ethnicity   nscore   escore   oscore  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    ascore   cscore  impuslive       ss  \n",
       "0 -0.91699 -0.00665   -0.21712 -1.18084  \n",
       "1  0.76096 -0.14277   -0.71126 -0.21575  \n",
       "2 -1.62090 -1.01450   -1.37983  0.40148  \n",
       "3  0.59042  0.58489   -1.37983 -1.18084  \n",
       "4 -0.30172  1.30612   -0.21712 -0.21575  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99bc1a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>amphet</th>\n",
       "      <th>amyl</th>\n",
       "      <th>benzos</th>\n",
       "      <th>caff</th>\n",
       "      <th>cannabis</th>\n",
       "      <th>choc</th>\n",
       "      <th>coke</th>\n",
       "      <th>crack</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  amphet  amyl  benzos  caff  cannabis  choc  coke  crack  ecstasy  \\\n",
       "0        1       0     0       0     1         0     1     0      0        0   \n",
       "1        1       0     0       0     1         1     1     1      0        1   \n",
       "2        1       0     0       0     1         1     1     0      0        0   \n",
       "3        1       0     0       1     1         0     1     0      0        0   \n",
       "4        1       0     0       0     1         1     1     0      0        0   \n",
       "\n",
       "   heroin  ketamine  legalh  lsd  meth  mushrooms  nicotine  vsa  \n",
       "0       0         0       0    0     0          0         0    0  \n",
       "1       0         0       0    0     1          0         1    0  \n",
       "2       0         0       0    0     0          0         0    0  \n",
       "3       0         0       0    0     0          0         0    0  \n",
       "4       0         0       0    0     0          0         0    0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary\n",
    "y_drugs = y_binary.drop(columns=['semer'])\n",
    "y_drugs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095b67b",
   "metadata": {},
   "source": [
    "## Algo 1. SDG binary clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff32deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following code, we recieved the warning message UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. \n",
    "# Use `zero_division` parameter to control this behavior\n",
    "\n",
    "# It highlights the issue if classes' imbalance. Certain fold in cross valdiation\n",
    "# had 0 for Precision. The presented precision in the output table is the averaged one from 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "992e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.5596   | 0.6262   | 0.9418\n",
      "amphet       | 0.7686   | 0.6905   | 0.6700   | 0.4131\n",
      "amyl         | 0.9297   | 0.6312   | 0.6697   | 0.1171\n",
      "benzos       | 0.7162   | 0.6719   | 0.7291   | 0.4292\n",
      "caff         | 0.9675   | 0.5996   | 0.5237   | 0.9788\n",
      "cannabis     | 0.5298   | 0.7961   | 0.7797   | 0.8255\n",
      "choc         | 0.9761   | 0.5814   | 0.6843   | 0.9813\n",
      "coke         | 0.7785   | 0.6462   | 0.6594   | 0.3395\n",
      "crack        | 0.9582   | 0.7165   | 0.6974   | 0.1078\n",
      "ecstasy      | 0.7255   | 0.7157   | 0.6882   | 0.5067\n",
      "heroin       | 0.9377   | 0.6197   | 0.5526   | 0.1285\n",
      "ketamine     | 0.8899   | 0.6699   | 0.6930   | 0.1994\n",
      "legalh       | 0.7009   | 0.7035   | 0.7540   | 0.5073\n",
      "lsd          | 0.7984   | 0.7910   | 0.7730   | 0.5081\n",
      "meth         | 0.8302   | 0.7299   | 0.7969   | 0.3345\n",
      "mushrooms    | 0.7699   | 0.7810   | 0.8214   | 0.4896\n",
      "nicotine     | 0.5623   | 0.6974   | 0.6675   | 0.7624\n",
      "vsa          | 0.9496   | 0.6415   | 0.5692   | 0.1032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# This will ignore only the UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip drugs with almost no users to prevent crashes\n",
    "    if y.sum() < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    sgd = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        max_iter=5000,\n",
    "        tol=1e-4,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    scoring = {\n",
    "        \"acc\": \"accuracy\",\n",
    "        \"bal_acc\": \"balanced_accuracy\",\n",
    "        \"precision\": \"precision\", \n",
    "        \"recall\": \"recall\",\n",
    "        \"f1\": \"f1\" \n",
    "    }\n",
    "\n",
    "    # Train\n",
    "    cv = cross_validate(sgd, X_train, y_train, scoring=scoring, cv=skf)\n",
    "    base = cross_validate(DummyClassifier(strategy=\"most_frequent\"),\n",
    "                          X_train, y_train, scoring=scoring, cv=skf)\n",
    "\n",
    "    # Output Row\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b2e7b",
   "metadata": {},
   "source": [
    "Same job but with hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fda53232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6341   | 0.6462   | 0.9576\n",
      "amphet       | 0.7686   | 0.7519   | 0.7739   | 0.4658\n",
      "amyl         | 0.9297   | 0.6803   | 0.6403   | 0.1492\n",
      "benzos       | 0.7162   | 0.7178   | 0.7338   | 0.4942\n",
      "caff         | 0.9675   | 0.6340   | 0.5902   | 0.9824\n",
      "cannabis     | 0.5298   | 0.8157   | 0.8022   | 0.8423\n",
      "choc         | 0.9761   | 0.5881   | 0.5368   | 0.9835\n",
      "coke         | 0.7785   | 0.7069   | 0.7127   | 0.4051\n",
      "crack        | 0.9582   | 0.7527   | 0.8064   | 0.1048\n",
      "ecstasy      | 0.7255   | 0.7501   | 0.7826   | 0.5130\n",
      "heroin       | 0.9377   | 0.7392   | 0.7649   | 0.1513\n",
      "ketamine     | 0.8899   | 0.7159   | 0.7709   | 0.2201\n",
      "legalh       | 0.7009   | 0.7748   | 0.7871   | 0.5874\n",
      "lsd          | 0.7984   | 0.8056   | 0.8355   | 0.4858\n",
      "meth         | 0.8302   | 0.7381   | 0.7774   | 0.3484\n",
      "mushrooms    | 0.7699   | 0.8068   | 0.8590   | 0.5113\n",
      "nicotine     | 0.5623   | 0.7127   | 0.7087   | 0.7642\n",
      "vsa          | 0.9496   | 0.6925   | 0.6817   | 0.1127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Ignore undefined precision/recall warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip drugs with almost no users\n",
    "    if y.sum() < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    scoring = {\n",
    "        \"acc\": \"accuracy\",\n",
    "        \"bal_acc\": \"balanced_accuracy\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "        \"f1\": \"f1\"\n",
    "    }\n",
    "\n",
    "    # -------------------------\n",
    "    # Baseline (Dummy)\n",
    "    # -------------------------\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # SGD + hyperparameter tuning\n",
    "    # -------------------------\n",
    "    sgd = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"alpha\": [1e-5, 1e-4, 1e-3],\n",
    "        \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "        \"l1_ratio\": [0.15, 0.5, 0.85],   # used only for elasticnet\n",
    "        \"max_iter\": [2000, 5000],\n",
    "        \"tol\": [1e-4, 1e-3]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=sgd,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",  # selection criterion\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_sgd = grid.best_estimator_\n",
    "\n",
    "    # -------------------------\n",
    "    # CV evaluation of BEST SGD\n",
    "    # -------------------------\n",
    "    cv = cross_validate(\n",
    "        best_sgd,\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Output row (same format)\n",
    "    # -------------------------\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77149f76",
   "metadata": {},
   "source": [
    "## Algo 2. Random Forest with OOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff8a4358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.5000   | 1.0000   | 0.9277\n",
      "amphet       | 0.7686   | 0.6151   | 0.3009   | 0.5615\n",
      "amyl         | 0.9297   | 0.4996   | 0.0000   | 0.0000\n",
      "benzos       | 0.7162   | 0.6068   | 0.3107   | 0.5588\n",
      "caff         | 0.9675   | 0.5000   | 1.0000   | 0.9675\n",
      "cannabis     | 0.5298   | 0.8151   | 0.8348   | 0.8214\n",
      "choc         | 0.9761   | 0.5000   | 1.0000   | 0.9761\n",
      "coke         | 0.7785   | 0.5442   | 0.1377   | 0.4423\n",
      "crack        | 0.9582   | 0.5000   | 0.0000   | 0.0000\n",
      "ecstasy      | 0.7255   | 0.6428   | 0.3961   | 0.5754\n",
      "heroin       | 0.9377   | 0.5050   | 0.0106   | 0.5000\n",
      "ketamine     | 0.8899   | 0.5087   | 0.0181   | 0.7500\n",
      "legalh       | 0.7009   | 0.6978   | 0.5100   | 0.6553\n",
      "lsd          | 0.7984   | 0.6699   | 0.4079   | 0.6019\n",
      "meth         | 0.8302   | 0.5785   | 0.1914   | 0.5326\n",
      "mushrooms    | 0.7699   | 0.6800   | 0.4496   | 0.6000\n",
      "nicotine     | 0.5623   | 0.7232   | 0.7889   | 0.7475\n",
      "vsa          | 0.9496   | 0.5000   | 0.0000   | 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip ultra-rare positives (also avoids RF/OOB edge cases)\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        # optional knobs:\n",
    "        # max_features=\"sqrt\",\n",
    "        # min_samples_leaf=2,\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # ---- OOB predictions (only where OOB proba exists) ----\n",
    "    oob_proba = rf.oob_decision_function_  # shape: (n_train, n_classes)\n",
    "    valid = ~np.isnan(oob_proba).any(axis=1)\n",
    "\n",
    "    # For binary classification, sklearn orders classes as rf.classes_\n",
    "    # We want predicted class labels.\n",
    "    oob_pred = rf.classes_[np.argmax(oob_proba[valid], axis=1)]\n",
    "    y_oob_true = y_train.iloc[valid] if hasattr(y_train, \"iloc\") else y_train[valid]\n",
    "\n",
    "    # ---- Baseline (Dummy) on train (single fit) ----\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    base_pred = dummy.predict(X_train)\n",
    "    base_acc = accuracy_score(y_train, base_pred)\n",
    "\n",
    "    # ---- Metrics on OOB ----\n",
    "    bal_acc = balanced_accuracy_score(y_oob_true, oob_pred)\n",
    "    rec = recall_score(y_oob_true, oob_pred, zero_division=0)\n",
    "    prec = precision_score(y_oob_true, oob_pred, zero_division=0)\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base_acc:.4f}   | \"\n",
    "          f\"{bal_acc:.4f}   | \"\n",
    "          f\"{rec:.4f}   | \"\n",
    "          f\"{prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5c7e4",
   "metadata": {},
   "source": [
    "Same job but with hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecf93273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.5492   | 0.9700   | 0.9346\n",
      "amphet       | 0.7686   | 0.7420   | 0.6963   | 0.4969\n",
      "amyl         | 0.9297   | 0.5758   | 0.2358   | 0.1748\n",
      "benzos       | 0.7162   | 0.6999   | 0.6379   | 0.5151\n",
      "caff         | 0.9675   | 0.5102   | 1.0000   | 0.9681\n",
      "cannabis     | 0.5298   | 0.8220   | 0.8260   | 0.8365\n",
      "choc         | 0.9761   | 0.5000   | 1.0000   | 0.9761\n",
      "coke         | 0.7785   | 0.6796   | 0.5569   | 0.4450\n",
      "crack        | 0.9582   | 0.6107   | 0.2857   | 0.1622\n",
      "ecstasy      | 0.7255   | 0.7446   | 0.7077   | 0.5508\n",
      "heroin       | 0.9377   | 0.6224   | 0.3191   | 0.2222\n",
      "ketamine     | 0.8899   | 0.6329   | 0.4096   | 0.2605\n",
      "legalh       | 0.7009   | 0.7537   | 0.6918   | 0.6154\n",
      "lsd          | 0.7984   | 0.7895   | 0.7401   | 0.5370\n",
      "meth         | 0.8302   | 0.7347   | 0.6211   | 0.4556\n",
      "mushrooms    | 0.7699   | 0.7899   | 0.7522   | 0.5662\n",
      "nicotine     | 0.5623   | 0.7238   | 0.7370   | 0.7659\n",
      "vsa          | 0.9496   | 0.5801   | 0.2237   | 0.1574\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameter grid (modest)\n",
    "# -----------------------------\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 500],\n",
    "    \"max_depth\": [None, 8, 15],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "keys = list(param_grid.keys())\n",
    "param_combinations = list(itertools.product(*[param_grid[k] for k in keys]))\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip ultra-rare positives / negatives\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Baseline (Dummy)\n",
    "    # -----------------------------\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    base_pred = dummy.predict(X_train)\n",
    "    base_acc = accuracy_score(y_train, base_pred)\n",
    "\n",
    "    # -----------------------------\n",
    "    # RF + OOB hyperparameter tuning\n",
    "    # -----------------------------\n",
    "    best_rf = None\n",
    "    best_oob_bal_acc = -np.inf\n",
    "\n",
    "    for values in param_combinations:\n",
    "        params = dict(zip(keys, values))\n",
    "\n",
    "        rf = RandomForestClassifier(\n",
    "            **params,\n",
    "            bootstrap=True,\n",
    "            oob_score=True,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "        )\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # ---- OOB predictions ----\n",
    "        oob_proba = rf.oob_decision_function_\n",
    "        valid = ~np.isnan(oob_proba).any(axis=1)\n",
    "        if valid.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        oob_pred = rf.classes_[np.argmax(oob_proba[valid], axis=1)]\n",
    "        y_oob_true = y_train.iloc[valid] if hasattr(y_train, \"iloc\") else y_train[valid]\n",
    "\n",
    "        oob_bal_acc = balanced_accuracy_score(y_oob_true, oob_pred)\n",
    "\n",
    "        if oob_bal_acc > best_oob_bal_acc:\n",
    "            best_oob_bal_acc = oob_bal_acc\n",
    "            best_rf = rf\n",
    "\n",
    "    # -----------------------------\n",
    "    # Final OOB metrics (best RF)\n",
    "    # -----------------------------\n",
    "    oob_proba = best_rf.oob_decision_function_\n",
    "    valid = ~np.isnan(oob_proba).any(axis=1)\n",
    "\n",
    "    oob_pred = best_rf.classes_[np.argmax(oob_proba[valid], axis=1)]\n",
    "    y_oob_true = y_train.iloc[valid] if hasattr(y_train, \"iloc\") else y_train[valid]\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(y_oob_true, oob_pred)\n",
    "    rec = recall_score(y_oob_true, oob_pred, zero_division=0)\n",
    "    prec = precision_score(y_oob_true, oob_pred, zero_division=0)\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base_acc:.4f}   | \"\n",
    "          f\"{bal_acc:.4f}   | \"\n",
    "          f\"{rec:.4f}   | \"\n",
    "          f\"{prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e9316e",
   "metadata": {},
   "source": [
    "## Algo 3. Support Vecotr Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc33da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6281   | 0.6784   | 0.9539\n",
      "amphet       | 0.7686   | 0.7498   | 0.7766   | 0.4596\n",
      "amyl         | 0.9297   | 0.6937   | 0.7169   | 0.1418\n",
      "benzos       | 0.7162   | 0.7141   | 0.7198   | 0.4953\n",
      "caff         | 0.9675   | 0.5923   | 0.6758   | 0.9763\n",
      "cannabis     | 0.5298   | 0.8152   | 0.7784   | 0.8558\n",
      "choc         | 0.9761   | 0.5923   | 0.6488   | 0.9830\n",
      "coke         | 0.7785   | 0.7154   | 0.7333   | 0.4082\n",
      "crack        | 0.9582   | 0.7240   | 0.7282   | 0.1020\n",
      "ecstasy      | 0.7255   | 0.7457   | 0.7609   | 0.5179\n",
      "heroin       | 0.9377   | 0.7591   | 0.8082   | 0.1566\n",
      "ketamine     | 0.8899   | 0.7131   | 0.7592   | 0.2201\n",
      "legalh       | 0.7009   | 0.7649   | 0.7805   | 0.5721\n",
      "lsd          | 0.7984   | 0.8076   | 0.8420   | 0.4849\n",
      "meth         | 0.8302   | 0.7288   | 0.7578   | 0.3404\n",
      "mushrooms    | 0.7699   | 0.8008   | 0.8272   | 0.5230\n",
      "nicotine     | 0.5623   | 0.7143   | 0.6922   | 0.7718\n",
      "vsa          | 0.9496   | 0.7033   | 0.7075   | 0.1105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=20000\n",
    "    )\n",
    "\n",
    "    cv = cross_validate(svm, X_train, y_train, scoring=scoring, cv=skf)\n",
    "\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6931ca",
   "metadata": {},
   "source": [
    "Same job but with hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c999e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision | Best params\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6281   | 0.6784   | 0.9539   | C=1, loss=squared_hinge\n",
      "amphet       | 0.7686   | 0.7498   | 0.7766   | 0.4596   | C=1, loss=squared_hinge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amyl         | 0.9297   | 0.6985   | 0.7450   | 0.1405   | C=1, loss=hinge\n",
      "benzos       | 0.7162   | 0.7141   | 0.7198   | 0.4953   | C=1, loss=squared_hinge\n",
      "caff         | 0.9675   | 0.6232   | 0.5709   | 0.9814   | C=0.01, loss=hinge\n",
      "cannabis     | 0.5298   | 0.8152   | 0.7772   | 0.8571   | C=0.1, loss=squared_hinge\n",
      "choc         | 0.9761   | 0.6399   | 0.6584   | 0.9861   | C=0.01, loss=hinge\n",
      "coke         | 0.7785   | 0.7213   | 0.7722   | 0.3996   | C=0.01, loss=hinge\n",
      "crack        | 0.9582   | 0.7348   | 0.7603   | 0.1028   | C=0.01, loss=squared_hinge\n",
      "ecstasy      | 0.7255   | 0.7497   | 0.7947   | 0.5060   | C=0.01, loss=hinge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heroin       | 0.9377   | 0.7652   | 0.8620   | 0.1471   | C=1, loss=hinge\n",
      "ketamine     | 0.8899   | 0.7235   | 0.8316   | 0.2109   | C=0.01, loss=hinge\n",
      "legalh       | 0.7009   | 0.7681   | 0.8049   | 0.5628   | C=0.01, loss=hinge\n",
      "lsd          | 0.7984   | 0.8076   | 0.8420   | 0.4849   | C=0.1, loss=squared_hinge\n",
      "meth         | 0.8302   | 0.7296   | 0.7578   | 0.3417   | C=0.1, loss=squared_hinge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mushrooms    | 0.7699   | 0.8035   | 0.8386   | 0.5201   | C=10, loss=hinge\n",
      "nicotine     | 0.5623   | 0.7218   | 0.6769   | 0.7897   | C=0.01, loss=hinge\n",
      "vsa          | 0.9496   | 0.7145   | 0.7600   | 0.1081   | C=0.1, loss=hinge\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- make precision/recall safe for rare positives (no warnings, no NaNs) ---\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "    \"f1\": make_scorer(f1_score, zero_division=0),\n",
    "}\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9} | Best params\")\n",
    "print(\"-\" * 105)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store best hyperparameters per drug (so you can reuse for test set later)\n",
    "best_params_svm = {}\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip ultra-rare positives / negatives\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---- Baseline (Dummy) ----\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # ---- Linear SVM ----\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=20000\n",
    "    )\n",
    "\n",
    "    # Hyperparameter grid (modest + standard)\n",
    "    # C controls regularization strength (bigger C = less regularization)\n",
    "    param_grid = {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    }\n",
    "\n",
    "    # NOTE: penalty=\"l1\" only works with loss=\"squared_hinge\" and dual=False.\n",
    "    # To keep things simple and robust, we tune only loss and C (very common).\n",
    "    # If you want L1 feature selection later, I can add a second grid safely.\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=svm,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",   # choose best by Bal Acc\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "    best_params_svm[drug] = grid.best_params_\n",
    "\n",
    "    # ---- CV metrics for the BEST hyperparameters ----\n",
    "    cv = cross_validate(\n",
    "        best_svm,\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # ---- Print row (same metrics + params) ----\n",
    "    params_str = f\"C={best_params_svm[drug]['C']}, loss={best_params_svm[drug]['loss']}\"\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}   | \"\n",
    "          f\"{params_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046cb26",
   "metadata": {},
   "source": [
    "## SHAP for the best model for Problem 2: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f8922c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x630 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 features by mean(|SHAP|) across CV training folds:\n",
      "age                       0.344189\n",
      "country                   0.185869\n",
      "gender                    0.114940\n",
      "ss                        0.097540\n",
      "nscore                    0.094661\n",
      "oscore                    0.042156\n",
      "escore                    0.032108\n",
      "cscore                    0.026924\n",
      "impuslive                 0.025152\n",
      "education                 0.024602\n",
      "ascore                    0.023033\n",
      "ethnicity                 0.011822\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SHAP on CV TRAINING FOLDS ONLY (for your X-only LinearSVC setup)\n",
    "# =========================\n",
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assumes these exist from your loop for the CURRENT drug:\n",
    "# X_train (DataFrame), y_train (Series), svm (LinearSVC)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_shap_values = []\n",
    "feature_names = X_train.columns  # requires X_train to be a pandas DataFrame\n",
    "\n",
    "for fold, (train_idx, _) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_tr = X_train.iloc[train_idx]\n",
    "    y_tr = y_train.iloc[train_idx]\n",
    "\n",
    "    # Fit a fresh model on this fold's training subset\n",
    "    svm_fold = clone(svm)\n",
    "    svm_fold.fit(X_tr, y_tr)\n",
    "\n",
    "    # Background set for SHAP (sample for speed)\n",
    "    background = shap.sample(X_tr, 200, random_state=42) if X_tr.shape[0] > 200 else X_tr\n",
    "\n",
    "    # LinearExplainer explains LinearSVC decision_function (margin)\n",
    "    explainer = shap.LinearExplainer(\n",
    "        svm_fold,\n",
    "        background,\n",
    "        feature_perturbation=\"interventional\"\n",
    "    )\n",
    "\n",
    "    # Compute SHAP values on TRAINING fold only (no test set, no val set)\n",
    "    shap_vals = explainer.shap_values(X_tr)\n",
    "\n",
    "    all_shap_values.append(shap_vals)\n",
    "\n",
    "# Stack all folds together: (sum_rows_over_folds, n_features)\n",
    "shap_values_cv = np.vstack(all_shap_values)\n",
    "\n",
    "# Global importance bar plot (no X needed -> avoids index problems)\n",
    "shap.summary_plot(\n",
    "    shap_values_cv,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    show=True\n",
    ")\n",
    "\n",
    "# Optional: print top features\n",
    "mean_abs_shap = np.abs(shap_values_cv).mean(axis=0)\n",
    "order = np.argsort(-mean_abs_shap)\n",
    "\n",
    "print(\"\\nTop 20 features by mean(|SHAP|) across CV training folds:\")\n",
    "for j in order[:20]:\n",
    "    print(f\"{feature_names[j]:<25} {mean_abs_shap[j]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450d74c",
   "metadata": {},
   "source": [
    "# Problem 3. One drug as target and others included in Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1f7ef",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b633365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>impuslive</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   gender  education  country  ethnicity   nscore   escore   oscore  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    ascore   cscore  impuslive       ss  \n",
       "0 -0.91699 -0.00665   -0.21712 -1.18084  \n",
       "1  0.76096 -0.14277   -0.71126 -0.21575  \n",
       "2 -1.62090 -1.01450   -1.37983  0.40148  \n",
       "3  0.59042  0.58489   -1.37983 -1.18084  \n",
       "4 -0.30172  1.30612   -0.21712 -0.21575  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba7931ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>amphet</th>\n",
       "      <th>amyl</th>\n",
       "      <th>benzos</th>\n",
       "      <th>caff</th>\n",
       "      <th>cannabis</th>\n",
       "      <th>choc</th>\n",
       "      <th>coke</th>\n",
       "      <th>crack</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  amphet  amyl  benzos  caff  cannabis  choc  coke  crack  ecstasy  \\\n",
       "0        1       0     0       0     1         0     1     0      0        0   \n",
       "1        1       0     0       0     1         1     1     1      0        1   \n",
       "2        1       0     0       0     1         1     1     0      0        0   \n",
       "3        1       0     0       1     1         0     1     0      0        0   \n",
       "4        1       0     0       0     1         1     1     0      0        0   \n",
       "\n",
       "   heroin  ketamine  legalh  lsd  meth  mushrooms  nicotine  vsa  \n",
       "0       0         0       0    0     0          0         0    0  \n",
       "1       0         0       0    0     1          0         1    0  \n",
       "2       0         0       0    0     0          0         0    0  \n",
       "3       0         0       0    0     0          0         0    0  \n",
       "4       0         0       0    0     0          0         0    0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0aab848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>...</th>\n",
       "      <th>crack</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   gender  education  country  ethnicity   nscore   escore   oscore  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    ascore   cscore  ...  crack  ecstasy  heroin  ketamine  legalh  lsd  meth  \\\n",
       "0 -0.91699 -0.00665  ...      0        0       0         0       0    0     0   \n",
       "1  0.76096 -0.14277  ...      0        1       0         0       0    0     1   \n",
       "2 -1.62090 -1.01450  ...      0        0       0         0       0    0     0   \n",
       "3  0.59042  0.58489  ...      0        0       0         0       0    0     0   \n",
       "4 -0.30172  1.30612  ...      0        0       0         0       0    0     0   \n",
       "\n",
       "   mushrooms  nicotine  vsa  \n",
       "0          0         0    0  \n",
       "1          0         1    0  \n",
       "2          0         0    0  \n",
       "3          0         0    0  \n",
       "4          0         0    0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's concatenate X and y for a while\n",
    "df_3 = pd.concat([X, y_drugs], axis=1)\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24351ec1",
   "metadata": {},
   "source": [
    "## Algo 1. SGD binary classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66ade9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.5913   | 0.6960   | 0.9483\n",
      "amphet       | 0.7686   | 0.7971   | 0.7936   | 0.5590\n",
      "amyl         | 0.9297   | 0.6767   | 0.6506   | 0.1429\n",
      "benzos       | 0.7162   | 0.7361   | 0.7574   | 0.5247\n",
      "caff         | 0.9675   | 0.5784   | 0.5634   | 0.9754\n",
      "cannabis     | 0.5298   | 0.8455   | 0.8322   | 0.8753\n",
      "choc         | 0.9761   | 0.5422   | 0.6094   | 0.9800\n",
      "coke         | 0.7785   | 0.7738   | 0.7085   | 0.6017\n",
      "crack        | 0.9582   | 0.7884   | 0.7000   | 0.2048\n",
      "ecstasy      | 0.7255   | 0.8228   | 0.8722   | 0.6084\n",
      "heroin       | 0.9377   | 0.7987   | 0.7842   | 0.2194\n",
      "ketamine     | 0.8899   | 0.7741   | 0.6695   | 0.4286\n",
      "legalh       | 0.7009   | 0.7957   | 0.7760   | 0.6505\n",
      "lsd          | 0.7984   | 0.8183   | 0.7496   | 0.6514\n",
      "meth         | 0.8302   | 0.7455   | 0.7498   | 0.4103\n",
      "mushrooms    | 0.7699   | 0.8272   | 0.8587   | 0.5687\n",
      "nicotine     | 0.5623   | 0.7328   | 0.6367   | 0.8310\n",
      "vsa          | 0.9496   | 0.7015   | 0.6942   | 0.1187\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    df = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    sgd = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        max_iter=5000,\n",
    "        tol=1e-4,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    scoring = {\n",
    "        \"acc\": \"accuracy\",\n",
    "        \"bal_acc\": \"balanced_accuracy\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "    }\n",
    "\n",
    "    # SGD CV\n",
    "    cv = cross_validate(sgd, X_train, y_train, scoring=scoring, cv=skf)\n",
    "\n",
    "    # Baseline CV\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a2d65",
   "metadata": {},
   "source": [
    "After hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a771a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6653   | 0.5955   | 0.9675\n",
      "amphet       | 0.7686   | 0.8179   | 0.8481   | 0.5471\n",
      "amyl         | 0.9297   | 0.7384   | 0.7165   | 0.1907\n",
      "benzos       | 0.7162   | 0.7699   | 0.7221   | 0.6113\n",
      "caff         | 0.9675   | 0.6546   | 0.6559   | 0.9828\n",
      "cannabis     | 0.5298   | 0.8623   | 0.8248   | 0.9032\n",
      "choc         | 0.9761   | 0.6081   | 0.7234   | 0.9831\n",
      "coke         | 0.7785   | 0.8454   | 0.8713   | 0.5791\n",
      "crack        | 0.9582   | 0.8467   | 0.8705   | 0.1796\n",
      "ecstasy      | 0.7255   | 0.8457   | 0.8551   | 0.6663\n",
      "heroin       | 0.9377   | 0.8324   | 0.8070   | 0.2767\n",
      "ketamine     | 0.8899   | 0.8439   | 0.8613   | 0.3828\n",
      "legalh       | 0.7009   | 0.8140   | 0.8247   | 0.6434\n",
      "lsd          | 0.7984   | 0.8576   | 0.8546   | 0.6196\n",
      "meth         | 0.8302   | 0.7898   | 0.7968   | 0.4363\n",
      "mushrooms    | 0.7699   | 0.8501   | 0.8586   | 0.6207\n",
      "nicotine     | 0.5623   | 0.7672   | 0.7570   | 0.8136\n",
      "vsa          | 0.9496   | 0.7348   | 0.7608   | 0.1226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score\n",
    "\n",
    "# Optional but recommended: avoid precision/recall warnings for rare positives\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "}\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Store best hyperparameters per drug so you can reuse later\n",
    "best_params_sgd_p3 = {}\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    df = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Base estimator (we'll tune key hyperparameters)\n",
    "    sgd = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    # Hyperparameter grid (modest but meaningful)\n",
    "    param_grid = {\n",
    "        \"alpha\": [1e-5, 1e-4, 1e-3],\n",
    "        \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "        \"l1_ratio\": [0.15, 0.5, 0.85],   # only used when penalty=\"elasticnet\"\n",
    "        \"max_iter\": [2000, 5000],\n",
    "        \"tol\": [1e-4, 1e-3],\n",
    "    }\n",
    "\n",
    "    # 1) Tune on training only (select by balanced accuracy)\n",
    "    grid = GridSearchCV(\n",
    "        estimator=sgd,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_sgd = grid.best_estimator_\n",
    "    best_params_sgd_p3[drug] = grid.best_params_   # stored, but NOT printed\n",
    "\n",
    "    # 2) Evaluate best model with CV to produce the same style table\n",
    "    cv = cross_validate(best_sgd, X_train, y_train, scoring=scoring, cv=skf)\n",
    "\n",
    "    # Baseline CV\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8c2b7",
   "metadata": {},
   "source": [
    "## Algo 2. Random Forest wit OOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7ae8f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.5000   | 1.0000   | 0.9277\n",
      "amphet       | 0.7686   | 0.7252   | 0.5186   | 0.6962\n",
      "amyl         | 0.9297   | 0.5084   | 0.0189   | 0.4000\n",
      "benzos       | 0.7162   | 0.7155   | 0.5070   | 0.7258\n",
      "caff         | 0.9675   | 0.5000   | 1.0000   | 0.9675\n",
      "cannabis     | 0.5298   | 0.8692   | 0.8836   | 0.8727\n",
      "choc         | 0.9761   | 0.5000   | 1.0000   | 0.9761\n",
      "coke         | 0.7785   | 0.7384   | 0.5389   | 0.7115\n",
      "crack        | 0.9582   | 0.5072   | 0.0159   | 0.3333\n",
      "ecstasy      | 0.7255   | 0.8119   | 0.7126   | 0.7526\n",
      "heroin       | 0.9377   | 0.5238   | 0.0532   | 0.3846\n",
      "ketamine     | 0.8899   | 0.6040   | 0.2229   | 0.6491\n",
      "legalh       | 0.7009   | 0.7831   | 0.6807   | 0.7173\n",
      "lsd          | 0.7984   | 0.7797   | 0.6184   | 0.7259\n",
      "meth         | 0.8302   | 0.6719   | 0.3750   | 0.7111\n",
      "mushrooms    | 0.7699   | 0.7949   | 0.6571   | 0.7451\n",
      "nicotine     | 0.5623   | 0.7701   | 0.8219   | 0.7894\n",
      "vsa          | 0.9496   | 0.5000   | 0.0000   | 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    df = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---------------- Random Forest (OOB) ----------------\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # ---- OOB predictions ----\n",
    "    oob_proba = rf.oob_decision_function_\n",
    "    valid = ~np.isnan(oob_proba).any(axis=1)\n",
    "\n",
    "    oob_pred = rf.classes_[np.argmax(oob_proba[valid], axis=1)]\n",
    "    y_oob_true = y_train.iloc[valid] if hasattr(y_train, \"iloc\") else y_train[valid]\n",
    "\n",
    "    rf_bal_acc = balanced_accuracy_score(y_oob_true, oob_pred)\n",
    "    rf_rec = recall_score(y_oob_true, oob_pred, zero_division=0)\n",
    "    rf_prec = precision_score(y_oob_true, oob_pred, zero_division=0)\n",
    "\n",
    "    # ---------------- Baseline (train, single fit) ----------------\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    base_pred = dummy.predict(X_train)\n",
    "    base_acc = accuracy_score(y_train, base_pred)\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base_acc:.4f}   | \"\n",
    "          f\"{rf_bal_acc:.4f}   | \"\n",
    "          f\"{rf_rec:.4f}   | \"\n",
    "          f\"{rf_prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd8c1f3",
   "metadata": {},
   "source": [
    "Hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3895d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.5956   | 0.9342   | 0.9416\n",
      "amphet       | 0.7686   | 0.8171   | 0.8138   | 0.5772\n",
      "amyl         | 0.9297   | 0.6609   | 0.3774   | 0.3390\n",
      "benzos       | 0.7162   | 0.7684   | 0.6729   | 0.6621\n",
      "caff         | 0.9675   | 0.5162   | 0.9712   | 0.9686\n",
      "cannabis     | 0.5298   | 0.8717   | 0.8874   | 0.8742\n",
      "choc         | 0.9761   | 0.5000   | 1.0000   | 0.9761\n",
      "coke         | 0.7785   | 0.8343   | 0.8024   | 0.6306\n",
      "crack        | 0.9582   | 0.6887   | 0.4127   | 0.3377\n",
      "ecstasy      | 0.7255   | 0.8574   | 0.8647   | 0.6858\n",
      "heroin       | 0.9377   | 0.7579   | 0.5638   | 0.4380\n",
      "ketamine     | 0.8899   | 0.8018   | 0.7108   | 0.4504\n",
      "legalh       | 0.7009   | 0.8231   | 0.8514   | 0.6389\n",
      "lsd          | 0.7984   | 0.8728   | 0.8651   | 0.6462\n",
      "meth         | 0.8302   | 0.7908   | 0.7070   | 0.5355\n",
      "mushrooms    | 0.7699   | 0.8660   | 0.8646   | 0.6608\n",
      "nicotine     | 0.5623   | 0.7744   | 0.7913   | 0.8075\n",
      "vsa          | 0.9496   | 0.6280   | 0.2895   | 0.3143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Store best hyperparameters per drug\n",
    "best_params_rf_p3 = {}\n",
    "\n",
    "# Modest hyperparameter grid (adjust for runtime)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 500],\n",
    "    \"max_depth\": [None, 8, 15],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "keys = list(param_grid.keys())\n",
    "param_combinations = list(itertools.product(*[param_grid[k] for k in keys]))\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    df = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---------------- Baseline (train, single fit) ----------------\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    base_pred = dummy.predict(X_train)\n",
    "    base_acc = accuracy_score(y_train, base_pred)\n",
    "\n",
    "    # ---------------- RF + OOB hyperparameter tuning ----------------\n",
    "    best_rf = None\n",
    "    best_oob_bal_acc = -np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for values in param_combinations:\n",
    "        params = dict(zip(keys, values))\n",
    "\n",
    "        rf = RandomForestClassifier(\n",
    "            **params,\n",
    "            bootstrap=True,\n",
    "            oob_score=True,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "        )\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # ---- OOB predictions ----\n",
    "        oob_proba = rf.oob_decision_function_\n",
    "        valid = ~np.isnan(oob_proba).any(axis=1)\n",
    "\n",
    "        # if OOB proba is unavailable for all rows (rare edge case)\n",
    "        if valid.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        oob_pred = rf.classes_[np.argmax(oob_proba[valid], axis=1)]\n",
    "        y_oob_true = y_train.iloc[valid] if hasattr(y_train, \"iloc\") else y_train[valid]\n",
    "\n",
    "        oob_bal_acc = balanced_accuracy_score(y_oob_true, oob_pred)\n",
    "\n",
    "        if oob_bal_acc > best_oob_bal_acc:\n",
    "            best_oob_bal_acc = oob_bal_acc\n",
    "            best_rf = rf\n",
    "            best_params = params\n",
    "\n",
    "    # Store best params (do not print)\n",
    "    best_params_rf_p3[drug] = best_params\n",
    "\n",
    "    # ---------------- Final OOB metrics for best RF ----------------\n",
    "    oob_proba = best_rf.oob_decision_function_\n",
    "    valid = ~np.isnan(oob_proba).any(axis=1)\n",
    "\n",
    "    oob_pred = best_rf.classes_[np.argmax(oob_proba[valid], axis=1)]\n",
    "    y_oob_true = y_train.iloc[valid] if hasattr(y_train, \"iloc\") else y_train[valid]\n",
    "\n",
    "    rf_bal_acc = balanced_accuracy_score(y_oob_true, oob_pred)\n",
    "    rf_rec = recall_score(y_oob_true, oob_pred, zero_division=0)\n",
    "    rf_prec = precision_score(y_oob_true, oob_pred, zero_division=0)\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base_acc:.4f}   | \"\n",
    "          f\"{rf_bal_acc:.4f}   | \"\n",
    "          f\"{rf_rec:.4f}   | \"\n",
    "          f\"{rf_prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658f08f",
   "metadata": {},
   "source": [
    "## Algo 3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f0e093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6813   | 0.6919   | 0.9644\n",
      "amphet       | 0.7686   | 0.8214   | 0.8395   | 0.5637\n",
      "amyl         | 0.9297   | 0.7478   | 0.7082   | 0.2014\n",
      "benzos       | 0.7162   | 0.7626   | 0.7057   | 0.6082\n",
      "caff         | 0.9675   | 0.6128   | 0.6922   | 0.9781\n",
      "cannabis     | 0.5298   | 0.8558   | 0.8273   | 0.8901\n",
      "choc         | 0.9761   | 0.6009   | 0.7555   | 0.9824\n",
      "coke         | 0.7785   | 0.8420   | 0.8502   | 0.5951\n",
      "crack        | 0.9582   | 0.8149   | 0.7474   | 0.2162\n",
      "ecstasy      | 0.7255   | 0.8419   | 0.8382   | 0.6733\n",
      "heroin       | 0.9377   | 0.8348   | 0.8181   | 0.2712\n",
      "ketamine     | 0.8899   | 0.8496   | 0.8676   | 0.3893\n",
      "legalh       | 0.7009   | 0.8150   | 0.8314   | 0.6416\n",
      "lsd          | 0.7984   | 0.8605   | 0.8714   | 0.5955\n",
      "meth         | 0.8302   | 0.7939   | 0.7812   | 0.4545\n",
      "mushrooms    | 0.7699   | 0.8548   | 0.8759   | 0.6143\n",
      "nicotine     | 0.5623   | 0.7665   | 0.7618   | 0.8106\n",
      "vsa          | 0.9496   | 0.7179   | 0.6808   | 0.1268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    df = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=20000\n",
    "    )\n",
    "\n",
    "    scoring = {\n",
    "        \"acc\": \"accuracy\",\n",
    "        \"bal_acc\": \"balanced_accuracy\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "    }\n",
    "\n",
    "    # SVM CV\n",
    "    cv = cross_validate(svm, X_train, y_train, scoring=scoring, cv=skf)\n",
    "\n",
    "    # Baseline CV\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50dffe0",
   "metadata": {},
   "source": [
    "Hyperparametrs tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3c45663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6813   | 0.6919   | 0.9644\n",
      "amphet       | 0.7686   | 0.8220   | 0.8424   | 0.5622\n",
      "amyl         | 0.9297   | 0.7676   | 0.7550   | 0.2062\n",
      "benzos       | 0.7162   | 0.7689   | 0.7267   | 0.6044\n",
      "caff         | 0.9675   | 0.6357   | 0.6580   | 0.9810\n",
      "cannabis     | 0.5298   | 0.8580   | 0.8260   | 0.8948\n",
      "choc         | 0.9761   | 0.6085   | 0.7385   | 0.9830\n",
      "coke         | 0.7785   | 0.8442   | 0.8562   | 0.5936\n",
      "crack        | 0.9582   | 0.8475   | 0.8410   | 0.2010\n",
      "ecstasy      | 0.7255   | 0.8489   | 0.8551   | 0.6743\n",
      "heroin       | 0.9377   | 0.8468   | 0.8825   | 0.2385\n",
      "ketamine     | 0.8899   | 0.8592   | 0.9039   | 0.3765\n",
      "legalh       | 0.7009   | 0.8207   | 0.8447   | 0.6436\n",
      "lsd          | 0.7984   | 0.8683   | 0.8977   | 0.5851\n",
      "meth         | 0.8302   | 0.8010   | 0.7968   | 0.4572\n",
      "mushrooms    | 0.7699   | 0.8608   | 0.8991   | 0.6042\n",
      "nicotine     | 0.5623   | 0.7671   | 0.7630   | 0.8109\n",
      "vsa          | 0.9496   | 0.7569   | 0.8142   | 0.1257\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Optional: silence convergence warnings (after we address the cause)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Safe scoring (avoids undefined precision/recall)\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store best hyperparameters per drug\n",
    "best_params_svm_p3 = {}\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    df = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---------------- Baseline (CV) ----------------\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # ---------------- Linear SVM ----------------\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=50000,   # ↑ increased to reduce convergence issues\n",
    "        tol=1e-3          # slightly relaxed tolerance (helps stability)\n",
    "    )\n",
    "\n",
    "    # Hyperparameter grid (focused & safe)\n",
    "    param_grid = {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    }\n",
    "\n",
    "    # 1) Tune on training set using CV\n",
    "    grid = GridSearchCV(\n",
    "        estimator=svm,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "    best_params_svm_p3[drug] = grid.best_params_   # stored, not printed\n",
    "\n",
    "    # 2) CV evaluation of BEST SVM (same table format)\n",
    "    cv = cross_validate(\n",
    "        best_svm,\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0bb35",
   "metadata": {},
   "source": [
    "## SHAP for the best model for Problem 3: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85d87bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "c:\\Users\\grzes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 features by mean(|SHAP|) across CV training folds:\n",
      "age                  0.248567\n",
      "legalh               0.134165\n",
      "country              0.099511\n",
      "nscore               0.074222\n",
      "benzos               0.063592\n",
      "mushrooms            0.058598\n",
      "nicotine             0.054992\n",
      "caff                 0.050655\n",
      "oscore               0.043523\n",
      "cannabis             0.042465\n",
      "coke                 0.041176\n",
      "ecstasy              0.039920\n",
      "alcohol              0.038474\n",
      "meth                 0.037604\n",
      "gender               0.036390\n",
      "ketamine             0.032332\n",
      "ss                   0.030700\n",
      "ascore               0.025987\n",
      "lsd                  0.024990\n",
      "amphet               0.024344\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SHAP on CV TRAINING FOLDS ONLY (LinearSVC)\n",
    "# =========================\n",
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assumes these already exist from your code:\n",
    "# X_train (DataFrame), y_train (Series), svm (LinearSVC), skf or StratifiedKFold settings\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_shap_values = []\n",
    "all_feature_names = X_train.columns\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_tr = X_train.iloc[train_idx]\n",
    "    y_tr = y_train.iloc[train_idx]\n",
    "\n",
    "    # Fit a fresh model on THIS fold's training subset\n",
    "    svm_fold = clone(svm)\n",
    "    svm_fold.fit(X_tr, y_tr)\n",
    "\n",
    "    # Background for SHAP (sample for speed)\n",
    "    background = shap.sample(X_tr, 200, random_state=42) if X_tr.shape[0] > 200 else X_tr\n",
    "\n",
    "    # SHAP explainer for linear SVM (explains decision_function margin)\n",
    "    explainer = shap.LinearExplainer(\n",
    "        svm_fold,\n",
    "        background,\n",
    "        feature_perturbation=\"interventional\"\n",
    "    )\n",
    "\n",
    "    # Compute SHAP values on TRAINING fold only (no test, no val)\n",
    "    shap_vals = explainer.shap_values(X_tr)\n",
    "\n",
    "    all_shap_values.append(shap_vals)\n",
    "\n",
    "# Stack all folds together: shape = (sum_train_rows_over_folds, n_features)\n",
    "shap_values_cv = np.vstack(all_shap_values)\n",
    "\n",
    "# Global importance bar plot (does NOT need X, avoids index issues)\n",
    "shap.summary_plot(\n",
    "    shap_values_cv,\n",
    "    feature_names=all_feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    show=True\n",
    ")\n",
    "\n",
    "# Optional: get a ranked importance table\n",
    "mean_abs_shap = np.abs(shap_values_cv).mean(axis=0)\n",
    "shap_importance = (\n",
    "    np.argsort(-mean_abs_shap)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 features by mean(|SHAP|) across CV training folds:\")\n",
    "for j in shap_importance[:20]:\n",
    "    print(f\"{all_feature_names[j]:<20} {mean_abs_shap[j]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbd8d6",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7efa51b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>impuslive</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   gender  education  country  ethnicity   nscore   escore   oscore  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    ascore   cscore  impuslive       ss  \n",
       "0 -0.91699 -0.00665   -0.21712 -1.18084  \n",
       "1  0.76096 -0.14277   -0.71126 -0.21575  \n",
       "2 -1.62090 -1.01450   -1.37983  0.40148  \n",
       "3  0.59042  0.58489   -1.37983 -1.18084  \n",
       "4 -0.30172  1.30612   -0.21712 -0.21575  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfc45e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>amphet</th>\n",
       "      <th>amyl</th>\n",
       "      <th>benzos</th>\n",
       "      <th>caff</th>\n",
       "      <th>cannabis</th>\n",
       "      <th>choc</th>\n",
       "      <th>coke</th>\n",
       "      <th>crack</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  amphet  amyl  benzos  caff  cannabis  choc  coke  crack  ecstasy  \\\n",
       "0        1       0     0       0     1         0     1     0      0        0   \n",
       "1        1       0     0       0     1         1     1     1      0        1   \n",
       "2        1       0     0       0     1         1     1     0      0        0   \n",
       "3        1       0     0       1     1         0     1     0      0        0   \n",
       "4        1       0     0       0     1         1     1     0      0        0   \n",
       "\n",
       "   heroin  ketamine  legalh  lsd  meth  mushrooms  nicotine  vsa  \n",
       "0       0         0       0    0     0          0         0    0  \n",
       "1       0         0       0    0     1          0         1    0  \n",
       "2       0         0       0    0     0          0         0    0  \n",
       "3       0         0       0    0     0          0         0    0  \n",
       "4       0         0       0    0     0          0         0    0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f28a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop ethnicity column, becase SHAP score for this feature from vladiation sets is low\n",
    "# 2. Add interaction varaibles such as featured_X[\"age_gender\"] = featured_X['age'] * featured_X['gender'] featured_X[\"age_country\"] = featured_X['age'] * featured_X['country']\n",
    "# 3. Perform PCA on every personality traits except for ss and nscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d6239",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "792cebb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC</th>\n",
       "      <th>Explained Variance Ratio</th>\n",
       "      <th>Cumulative Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC1</td>\n",
       "      <td>0.325110</td>\n",
       "      <td>0.325110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC2</td>\n",
       "      <td>0.283941</td>\n",
       "      <td>0.609051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC3</td>\n",
       "      <td>0.167449</td>\n",
       "      <td>0.776499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC4</td>\n",
       "      <td>0.128880</td>\n",
       "      <td>0.905379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PC5</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PC  Explained Variance Ratio  Cumulative Variance\n",
       "0  PC1                  0.325110             0.325110\n",
       "1  PC2                  0.283941             0.609051\n",
       "2  PC3                  0.167449             0.776499\n",
       "3  PC4                  0.128880             0.905379\n",
       "4  PC5                  0.094621             1.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Select personality traits\n",
    "traits = X[['escore', 'oscore', 'ascore', 'cscore', 'impuslive']]\n",
    "\n",
    "# Fit PCA (EDA only)\n",
    "pca = PCA()\n",
    "pca.fit(traits)\n",
    "\n",
    "# Explained variance table\n",
    "explained_variance = pd.DataFrame({\n",
    "    \"PC\": [f\"PC{i+1}\" for i in range(len(pca.explained_variance_ratio_))],\n",
    "    \"Explained Variance Ratio\": pca.explained_variance_ratio_,\n",
    "    \"Cumulative Variance\": pca.explained_variance_ratio_.cumsum()\n",
    "})\n",
    "\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acfb1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will take PC1 and PC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad10da1",
   "metadata": {},
   "source": [
    "## Final featured dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca0293c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ethinicity\n",
    "X_featured = X.drop(columns=['ethnicity'])\n",
    "\n",
    "# Add interaction variables\n",
    "X_featured[\"age_gender\"] = X_featured['age'] * X_featured['gender'] \n",
    "X_featured[\"age_country\"] = X_featured['age'] * X_featured['country']\n",
    "\n",
    "# For PCA dimension reduction of personlaity traits, I wll use PC1 and PC2, which explain together 60% of variance...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44bacc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>amphet</th>\n",
       "      <th>amyl</th>\n",
       "      <th>benzos</th>\n",
       "      <th>caff</th>\n",
       "      <th>cannabis</th>\n",
       "      <th>choc</th>\n",
       "      <th>coke</th>\n",
       "      <th>crack</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  amphet  amyl  benzos  caff  cannabis  choc  coke  crack  ecstasy  \\\n",
       "0        1       0     0       0     1         0     1     0      0        0   \n",
       "1        1       0     0       0     1         1     1     1      0        1   \n",
       "2        1       0     0       0     1         1     1     0      0        0   \n",
       "3        1       0     0       1     1         0     1     0      0        0   \n",
       "4        1       0     0       0     1         1     1     0      0        0   \n",
       "\n",
       "   heroin  ketamine  legalh  lsd  meth  mushrooms  nicotine  vsa  \n",
       "0       0         0       0    0     0          0         0    0  \n",
       "1       0         0       0    0     1          0         1    0  \n",
       "2       0         0       0    0     0          0         0    0  \n",
       "3       0         0       0    0     0          0         0    0  \n",
       "4       0         0       0    0     0          0         0    0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_drugs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072e18a",
   "metadata": {},
   "source": [
    "Let's run again SVM algorithm only for classification task. Random Forest in general learn more quickly nonlinear relations, so adding interaction varaibles should not have many added value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075be16",
   "metadata": {},
   "source": [
    "##  Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ff7611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision | Best params\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6162   | 0.6475   | 0.9524   | C=0.01, loss=hinge\n",
      "amphet       | 0.7686   | 0.7538   | 0.7967   | 0.4554   | C=0.1, loss=squared_hinge\n",
      "amyl         | 0.9297   | 0.6857   | 0.7173   | 0.1362   | C=0.01, loss=squared_hinge\n",
      "benzos       | 0.7162   | 0.7064   | 0.7127   | 0.4859   | C=1, loss=squared_hinge\n",
      "caff         | 0.9675   | 0.6164   | 0.6395   | 0.9792   | C=0.1, loss=squared_hinge\n",
      "cannabis     | 0.5298   | 0.8067   | 0.7672   | 0.8494   | C=10, loss=hinge\n",
      "choc         | 0.9761   | 0.5979   | 0.6957   | 0.9828   | C=0.1, loss=squared_hinge\n",
      "coke         | 0.7785   | 0.7133   | 0.7783   | 0.3861   | C=0.01, loss=hinge\n",
      "crack        | 0.9582   | 0.7555   | 0.8564   | 0.0986   | C=0.01, loss=hinge\n",
      "ecstasy      | 0.7255   | 0.7513   | 0.7778   | 0.5184   | C=0.1, loss=hinge\n",
      "heroin       | 0.9377   | 0.7652   | 0.8515   | 0.1501   | C=0.01, loss=hinge\n",
      "ketamine     | 0.8899   | 0.7200   | 0.7895   | 0.2183   | C=0.01, loss=squared_hinge\n",
      "legalh       | 0.7009   | 0.7627   | 0.7694   | 0.5763   | C=1, loss=hinge\n",
      "lsd          | 0.7984   | 0.8085   | 0.8255   | 0.5005   | C=0.01, loss=squared_hinge\n",
      "meth         | 0.8302   | 0.7383   | 0.7929   | 0.3390   | C=0.01, loss=hinge\n",
      "mushrooms    | 0.7699   | 0.7989   | 0.8011   | 0.5409   | C=0.1, loss=hinge\n",
      "nicotine     | 0.5623   | 0.7187   | 0.6662   | 0.7895   | C=0.01, loss=hinge\n",
      "vsa          | 0.9496   | 0.7243   | 0.7867   | 0.1093   | C=0.01, loss=hinge\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- make precision/recall safe for rare positives (no warnings, no NaNs) ---\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "    \"f1\": make_scorer(f1_score, zero_division=0),\n",
    "}\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9} | Best params\")\n",
    "print(\"-\" * 105)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store best hyperparameters per drug (so you can reuse for test set later)\n",
    "best_params_svm = {}\n",
    "\n",
    "# -----\n",
    "# Use your engineered features\n",
    "# -----\n",
    "X_used = X_featured\n",
    "\n",
    "# Traits to PCA -> PC1, PC2 (use your actual column spelling)\n",
    "pca_traits = ['escore', 'oscore', 'ascore', 'cscore', 'impuslive']\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip ultra-rare positives / negatives\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_used, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---- Baseline (Dummy) ----\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # ---- Fold-safe PCA + Linear SVM ----\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"pca_traits\", PCA(n_components=2, random_state=42), pca_traits),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=200000,   # << increased a lot to reduce convergence warnings\n",
    "        tol=1e-4           # you can try 1e-3 if you want faster / less strict convergence\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", svm)\n",
    "    ])\n",
    "\n",
    "    # Hyperparameter grid (modest + standard)\n",
    "    param_grid = {\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "        \"clf__loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",   # choose best by Bal Acc\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "    best_params_svm[drug] = grid.best_params_\n",
    "\n",
    "    # ---- CV metrics for the BEST hyperparameters ----\n",
    "    cv = cross_validate(\n",
    "        best_svm,\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # ---- Print row (same metrics + params) ----\n",
    "    params_str = f\"C={best_params_svm[drug]['clf__C']}, loss={best_params_svm[drug]['clf__loss']}\"\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}   | \"\n",
    "          f\"{params_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd02ac",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44d4fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9277   | 0.6707   | 0.6712   | 0.9632\n",
      "amphet       | 0.7686   | 0.8210   | 0.8482   | 0.5554\n",
      "amyl         | 0.9297   | 0.7560   | 0.7359   | 0.1993\n",
      "benzos       | 0.7162   | 0.7671   | 0.7267   | 0.5996\n",
      "caff         | 0.9675   | 0.6321   | 0.6909   | 0.9800\n",
      "cannabis     | 0.5298   | 0.8547   | 0.8222   | 0.8919\n",
      "choc         | 0.9761   | 0.5846   | 0.7229   | 0.9817\n",
      "coke         | 0.7785   | 0.8331   | 0.8323   | 0.5898\n",
      "crack        | 0.9582   | 0.8367   | 0.8256   | 0.1915\n",
      "ecstasy      | 0.7255   | 0.8487   | 0.8455   | 0.6845\n",
      "heroin       | 0.9377   | 0.8482   | 0.8825   | 0.2417\n",
      "ketamine     | 0.8899   | 0.8587   | 0.9037   | 0.3749\n",
      "legalh       | 0.7009   | 0.8205   | 0.8359   | 0.6511\n",
      "lsd          | 0.7984   | 0.8725   | 0.8978   | 0.5978\n",
      "meth         | 0.8302   | 0.8039   | 0.8202   | 0.4425\n",
      "mushrooms    | 0.7699   | 0.8649   | 0.8875   | 0.6295\n",
      "nicotine     | 0.5623   | 0.7688   | 0.7618   | 0.8140\n",
      "vsa          | 0.9496   | 0.7664   | 0.8408   | 0.1264\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Optional: silence convergence warnings (after we address the cause)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Safe scoring (avoids undefined precision/recall)\n",
    "scoring = {\n",
    "    \"acc\": \"accuracy\",\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store best hyperparameters per drug\n",
    "best_params_svm_p3 = {}\n",
    "\n",
    "# Traits -> PCA -> PC1/PC2 (use your actual column spelling)\n",
    "pca_traits = ['escore', 'oscore', 'ascore', 'cscore', 'impuslive']\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    # X = engineered X + other drugs (excluding target)\n",
    "    other_drugs = y_drugs.drop(columns=[drug])\n",
    "    df = pd.concat([X_featured, other_drugs], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---------------- Baseline (CV) ----------------\n",
    "    base = cross_validate(\n",
    "        DummyClassifier(strategy=\"most_frequent\"),\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    # ---------------- Fold-safe PCA + Linear SVM ----------------\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"pca_traits\", PCA(n_components=2, random_state=42), pca_traits),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=200000,   # ↑ more headroom than 50k\n",
    "        tol=1e-3           # relaxed tolerance helps convergence\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", svm)\n",
    "    ])\n",
    "\n",
    "    # Hyperparameter grid (focused & safe)\n",
    "    param_grid = {\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "        \"clf__loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    }\n",
    "\n",
    "    # 1) Tune on training set using CV (PCA is refit each fold automatically)\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "    best_params_svm_p3[drug] = grid.best_params_   # stored, not printed\n",
    "\n",
    "    # 2) CV evaluation of BEST SVM (same table format)\n",
    "    cv = cross_validate(\n",
    "        best_svm,\n",
    "        X_train, y_train,\n",
    "        scoring=scoring,\n",
    "        cv=skf\n",
    "    )\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base['test_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_bal_acc'].mean():.4f}   | \"\n",
    "          f\"{cv['test_recall'].mean():.4f}   | \"\n",
    "          f\"{cv['test_precision'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a6362",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "The performance metrics did not improve significantly after feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ac773",
   "metadata": {},
   "source": [
    "# Running SVM on the test set - classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c003f2",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78026f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9284   | 0.5950   | 0.6714   | 0.9476\n",
      "amphet       | 0.7692   | 0.7615   | 0.7816   | 0.4755\n",
      "amyl         | 0.9284   | 0.7160   | 0.7778   | 0.1479\n",
      "benzos       | 0.7162   | 0.7014   | 0.7103   | 0.4780\n",
      "caff         | 0.9682   | 0.6553   | 0.6438   | 0.9833\n",
      "cannabis     | 0.5305   | 0.8337   | 0.8200   | 0.8586\n",
      "choc         | 0.9761   | 0.4873   | 0.6413   | 0.9752\n",
      "coke         | 0.7798   | 0.6869   | 0.6867   | 0.3826\n",
      "crack        | 0.9576   | 0.7262   | 0.8125   | 0.0909\n",
      "ecstasy      | 0.7268   | 0.7552   | 0.7184   | 0.5649\n",
      "heroin       | 0.9363   | 0.7714   | 0.9167   | 0.1429\n",
      "ketamine     | 0.8886   | 0.6930   | 0.6905   | 0.2214\n",
      "legalh       | 0.7003   | 0.8092   | 0.8230   | 0.6327\n",
      "lsd          | 0.7984   | 0.8411   | 0.8947   | 0.5152\n",
      "meth         | 0.8302   | 0.7827   | 0.8594   | 0.3741\n",
      "mushrooms    | 0.7692   | 0.7914   | 0.8621   | 0.4808\n",
      "nicotine     | 0.5623   | 0.6837   | 0.6462   | 0.7486\n",
      "vsa          | 0.9496   | 0.7353   | 0.8421   | 0.1074\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "def strip_pipeline_prefix(params: dict, prefix: str = \"clf__\") -> dict:\n",
    "    \"\"\"\n",
    "    If params come from a Pipeline grid search, they may be like 'clf__C'.\n",
    "    This converts them to 'C' so they can be passed to LinearSVC directly.\n",
    "    If there is no prefix, it returns params unchanged.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for k, v in params.items():\n",
    "        if k.startswith(prefix):\n",
    "            out[k[len(prefix):]] = v\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # Skip ultra-rare positives / negatives\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    # Reproducible split (same every run with same X/y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ----- Baseline (Dummy) on TEST -----\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    base_pred = dummy.predict(X_test)\n",
    "    base_acc = accuracy_score(y_test, base_pred)\n",
    "\n",
    "    # ----- Best SVM on TEST -----\n",
    "    if drug not in best_params_svm:\n",
    "        continue  # safety: only evaluate drugs we tuned\n",
    "\n",
    "    # Handle both cases:\n",
    "    # - params stored as {'C': ..., 'loss': ...}\n",
    "    # - params stored from a Pipeline as {'clf__C': ..., 'clf__loss': ...}\n",
    "    params = strip_pipeline_prefix(best_params_svm[drug], prefix=\"clf__\")\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=20000,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "    test_pred = svm.predict(X_test)\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(y_test, test_pred)\n",
    "    rec = recall_score(y_test, test_pred, zero_division=0)\n",
    "    prec = precision_score(y_test, test_pred, zero_division=0)\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base_acc:.4f}   | \"\n",
    "          f\"{bal_acc:.4f}   | \"\n",
    "          f\"{rec:.4f}   | \"\n",
    "          f\"{prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1206f2c2",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2287eb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug         | Base Acc | Bal Acc  | Recall   | Precision\n",
      "-----------------------------------------------------------------\n",
      "alcohol      | 0.9284   | 0.6150   | 0.7114   | 0.9504\n",
      "amphet       | 0.7692   | 0.8109   | 0.8391   | 0.5368\n",
      "amyl         | 0.9284   | 0.8203   | 0.8148   | 0.2651\n",
      "benzos       | 0.7162   | 0.7534   | 0.7290   | 0.5652\n",
      "caff         | 0.9682   | 0.5788   | 0.6575   | 0.9756\n",
      "cannabis     | 0.5305   | 0.8679   | 0.8600   | 0.8866\n",
      "choc         | 0.9761   | 0.5226   | 0.7120   | 0.9776\n",
      "coke         | 0.7798   | 0.8623   | 0.8675   | 0.6316\n",
      "crack        | 0.9576   | 0.8641   | 0.8750   | 0.2090\n",
      "ecstasy      | 0.7268   | 0.8499   | 0.8641   | 0.6642\n",
      "heroin       | 0.9363   | 0.8828   | 0.9583   | 0.2527\n",
      "ketamine     | 0.8886   | 0.8494   | 0.8810   | 0.3776\n",
      "legalh       | 0.7003   | 0.8370   | 0.8407   | 0.6835\n",
      "lsd          | 0.7984   | 0.8741   | 0.9211   | 0.5738\n",
      "meth         | 0.8302   | 0.8117   | 0.8438   | 0.4390\n",
      "mushrooms    | 0.7692   | 0.8126   | 0.8046   | 0.5738\n",
      "nicotine     | 0.5623   | 0.7349   | 0.7547   | 0.7729\n",
      "vsa          | 0.9496   | 0.7397   | 0.7895   | 0.1190\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f\"{'Drug':<12} | {'Base Acc':<8} | {'Bal Acc':<8} | {'Recall':<8} | {'Precision':<9}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "def strip_pipeline_prefix(params: dict, prefix: str = \"clf__\") -> dict:\n",
    "    \"\"\"\n",
    "    If params come from a Pipeline grid search, they may be like 'clf__C'.\n",
    "    This converts them to 'C' so they can be passed to LinearSVC directly.\n",
    "    If there is no prefix, it returns params unchanged.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for k, v in params.items():\n",
    "        out[k[len(prefix):]] = v if k.startswith(prefix) else v\n",
    "        if not k.startswith(prefix):\n",
    "            out[k] = v\n",
    "    # The above would duplicate keys for non-prefixed params; fix cleanly:\n",
    "    out = { (k[len(prefix):] if k.startswith(prefix) else k): v for k, v in params.items() }\n",
    "    return out\n",
    "\n",
    "for drug in y_drugs.columns:\n",
    "    y = y_drugs[drug]\n",
    "\n",
    "    # X = original X + other drugs (excluding target)\n",
    "    Xp3 = df_3.drop(columns=[drug])\n",
    "\n",
    "    # Skip ultra-rare targets\n",
    "    if y.sum() < 2 or (y.shape[0] - y.sum()) < 2:\n",
    "        continue\n",
    "\n",
    "    # Same split as tuning cell (reproducible)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Xp3, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ---------- Baseline (Dummy) on TEST ----------\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train, y_train)\n",
    "    base_pred = dummy.predict(X_test)\n",
    "    base_acc = accuracy_score(y_test, base_pred)\n",
    "\n",
    "    # ---------- Best SVM on TEST ----------\n",
    "    if drug not in best_params_svm_p3:\n",
    "        continue  # safety\n",
    "\n",
    "    params = strip_pipeline_prefix(best_params_svm_p3[drug], prefix=\"clf__\")\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        max_iter=50000,   # same as your tuning cell\n",
    "        tol=1e-3,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "    test_pred = svm.predict(X_test)\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(y_test, test_pred)\n",
    "    rec = recall_score(y_test, test_pred, zero_division=0)\n",
    "    prec = precision_score(y_test, test_pred, zero_division=0)\n",
    "\n",
    "    print(f\"{drug:<12} | \"\n",
    "          f\"{base_acc:.4f}   | \"\n",
    "          f\"{bal_acc:.4f}   | \"\n",
    "          f\"{rec:.4f}   | \"\n",
    "          f\"{prec:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
